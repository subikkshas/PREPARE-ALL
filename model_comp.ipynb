{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtu7xurWvjUtgExGGIgFra",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subikkshas/PREPARE-ALL/blob/main/model_comp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "tRNbiY6SXyX6"
      },
      "outputs": [],
      "source": [
        "### function to remove features\n",
        "import pandas as pd\n",
        "def remove_columns(df, feature_set='normal'):\n",
        "\n",
        "    # Define base leakage columns to always remove\n",
        "    base_leakage_cols = [\n",
        "        \"Sl No\",\n",
        "        \"UPN_AI_dataset\",\n",
        "        # All Date columns\n",
        "        \"Date of Birth\", \"Date of Diagnosis\", \"Date of Remission_EOI\",\n",
        "        \"Date of Completion of treatment\", \"Date of Relapse\",\n",
        "        \"Date of Death \", \"Date of Treatment abandonment/ Disease progresssion/Off protocol\",\n",
        "        \"Date of Last FU\",\n",
        "        # Relapse & outcome details\n",
        "        \"Time-point of Relapse \", \"Type of relapse\", \"Site of Relapse \",\n",
        "        \"Death\", \"Treatment death phase\",\n",
        "        \"Treatment abandonment/Disease progresssion/Off protocol\",\n",
        "        \"Current status at Last Follow up \", \"Remission status _EOI\"\n",
        "    ]\n",
        "\n",
        "    # Additional columns to remove for minimal feature set\n",
        "    minimal_cols = [\n",
        "        \"Previous Treatment\", \"NCI Risk\", \"Lineage\", \"Bulky Disease\",\n",
        "        \"CNS Disease\", \"Detail cytogenetics\", \"Provisional risk\",\n",
        "    ]\n",
        "\n",
        "    # Combine columns based on feature_set parameter\n",
        "    if feature_set == 'minimal':\n",
        "        cols_to_remove = base_leakage_cols + minimal_cols\n",
        "    else:  # 'normal' or any other value\n",
        "        cols_to_remove = base_leakage_cols\n",
        "\n",
        "    # Remove only columns that exist in the dataframe\n",
        "    existing_cols_to_remove = [c for c in cols_to_remove if c in df.columns]\n",
        "    df_clean = df.drop(columns=existing_cols_to_remove)\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "\n",
        "\n",
        "### function to clean string columns\n",
        "def clean_string_columns(df, columns_to_clean):\n",
        "  existing_cols_to_clean = [col for col in columns_to_clean if col in df.columns]\n",
        "\n",
        "  for col in existing_cols_to_clean:\n",
        "      df[col] = df[col].astype(\"string\").str.strip().str.lower()\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "\n",
        "### function to remove entry which are not in remission\n",
        "def filter_remission_status(df):\n",
        "  if 'Remission status _EOI' in df.columns:\n",
        "    # Filter out 'not in remission' records (case-insensitive) but keep <NA>\n",
        "    df_filter = df[df['Remission status _EOI'].astype(str).str.lower() != 'not in remission'].copy()\n",
        "    print(f\"Original dataset shape: {df.shape}\")\n",
        "    print(f\"Filtered dataset shape: {df_filter.shape}\")\n",
        "    print(f\"Number of rows removed: {df.shape[0] - df_filter.shape[0]}\")\n",
        "    return df_filter\n",
        "\n",
        "  else:\n",
        "    print(\"Column 'Remission status _EOI' not found in the DataFrame.\")\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "### funtion to split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "def split_data(df, target_col=\"Relapsed\", test_size=0.20, random_state=42, stratify=True):\n",
        "\n",
        "    # Check if target column exists\n",
        "    if target_col not in df.columns:\n",
        "        raise ValueError(f\"Target column '{target_col}' not found in dataframe\")\n",
        "\n",
        "    # Prepare features and target\n",
        "    X = df.drop(columns=[target_col])\n",
        "    y = df[target_col].astype(\"category\").cat.codes  # Convert Yes/No to 0/1\n",
        "\n",
        "    # Split data\n",
        "    if stratify:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=42, stratify=y\n",
        "        )\n",
        "    else:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=42\n",
        "        )\n",
        "\n",
        "    # Print summary\n",
        "    print(\"Data split summary:\")\n",
        "    print(f\"X_train shape: {X_train.shape}\")\n",
        "    print(f\"X_test shape: {X_test.shape}\")\n",
        "    print(f\"y_train shape: {y_train.shape}\")\n",
        "    print(f\"y_test shape: {y_test.shape}\")\n",
        "    print(f\"Training set class distribution: {dict(zip(y_train.value_counts().index, y_train.value_counts().values))}\")\n",
        "    print(f\"Test set class distribution: {dict(zip(y_test.value_counts().index, y_test.value_counts().values))}\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "\n",
        "### function to load the data from drive\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def load_train_test_data(load_path='/content/drive/MyDrive/test_data/'):\n",
        "    # Mount Google Drive (if not already mounted)\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        print(\"Google Drive mounted successfully.\")\n",
        "    except:\n",
        "        print(\"Google Drive already mounted or mounting failed.\")\n",
        "\n",
        "    # Load the data files\n",
        "    try:\n",
        "        loaded_X_train = pd.read_csv(os.path.join(load_path, 'X_train.csv'))\n",
        "        loaded_y_train = pd.read_csv(os.path.join(load_path, 'y_train.csv'))\n",
        "        loaded_X_test = pd.read_csv(os.path.join(load_path, 'X_test.csv'))\n",
        "        loaded_y_test = pd.read_csv(os.path.join(load_path, 'y_test.csv'))\n",
        "\n",
        "        print(\"Data loaded successfully!\")\n",
        "        print(f\"X_train shape: {loaded_X_train.shape}\")\n",
        "        print(f\"y_train shape: {loaded_y_train.shape}\")\n",
        "        print(f\"X_test shape: {loaded_X_test.shape}\")\n",
        "        print(f\"y_test shape: {loaded_y_test.shape}\")\n",
        "\n",
        "        return loaded_X_train, loaded_y_train, loaded_X_test, loaded_y_test\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: File not found - {e}\")\n",
        "        return None, None, None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "\n",
        "\n",
        "### function for imputation\n",
        "from sklearn.impute import SimpleImputer\n",
        "import pandas as pd\n",
        "from typing import List, Tuple, Dict\n",
        "\n",
        "def impute_train_test(\n",
        "    X_train: pd.DataFrame,\n",
        "    X_test: pd.DataFrame,\n",
        "    categorical_cols: List[str],\n",
        "    numeric_cols: List[str],\n",
        "    numeric_strategy: str = \"median\",\n",
        ") -> Tuple[pd.DataFrame, pd.DataFrame, Dict[str, SimpleImputer]]:\n",
        "    \"\"\"\n",
        "    Fit imputers on X_train and transform both X_train and X_test.\n",
        "    - Categorical: most_frequent\n",
        "    - Numeric: numeric_strategy (default median)\n",
        "\n",
        "    Returns:\n",
        "        X_train_imp, X_test_imp, {'cat': cat_imputer, 'num': num_imputer}\n",
        "    \"\"\"\n",
        "    # Safety: work on copies\n",
        "    X_train_imp = X_train.copy()\n",
        "    X_test_imp  = X_test.copy()\n",
        "\n",
        "    # Filter to existing columns (avoids KeyErrors if lists have extras)\n",
        "    cat_cols_exist = [c for c in categorical_cols if c in X_train.columns]\n",
        "    num_cols_exist = [c for c in numeric_cols if c in X_train.columns]\n",
        "\n",
        "    # Define imputers\n",
        "    cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "    num_imputer = SimpleImputer(strategy=numeric_strategy)\n",
        "\n",
        "    # --- Fit on TRAIN ---\n",
        "    if cat_cols_exist:\n",
        "        X_train_imp[cat_cols_exist] = cat_imputer.fit_transform(X_train_imp[cat_cols_exist])\n",
        "        # Cast back to object to keep them categorical-like\n",
        "        for c in cat_cols_exist:\n",
        "            X_train_imp[c] = X_train_imp[c].astype(object)\n",
        "\n",
        "    if num_cols_exist:\n",
        "        X_train_imp[num_cols_exist] = num_imputer.fit_transform(X_train_imp[num_cols_exist])\n",
        "        # Ensure numeric dtype\n",
        "        for c in num_cols_exist:\n",
        "            X_train_imp[c] = pd.to_numeric(X_train_imp[c], errors=\"coerce\")\n",
        "\n",
        "    # --- Transform TEST with the same fitted imputers ---\n",
        "    # If test is missing some listed columns, skip them gracefully\n",
        "    cat_cols_test = [c for c in cat_cols_exist if c in X_test_imp.columns]\n",
        "    num_cols_test = [c for c in num_cols_exist if c in X_test_imp.columns]\n",
        "\n",
        "    if cat_cols_test:\n",
        "        X_test_imp[cat_cols_test] = cat_imputer.transform(X_test_imp[cat_cols_test])\n",
        "        for c in cat_cols_test:\n",
        "            X_test_imp[c] = X_test_imp[c].astype(object)\n",
        "\n",
        "    if num_cols_test:\n",
        "        X_test_imp[num_cols_test] = num_imputer.transform(X_test_imp[num_cols_test])\n",
        "        for c in num_cols_test:\n",
        "            X_test_imp[c] = pd.to_numeric(X_test_imp[c], errors=\"coerce\")\n",
        "\n",
        "    imputers = {\"cat\": cat_imputer, \"num\": num_imputer}\n",
        "    return X_train_imp, X_test_imp, imputers\n",
        "\n",
        "\n",
        "\n",
        "### function for encoding\n",
        "from typing import Dict, List, Tuple, Union\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "def encode_data_simple(\n",
        "    X_train: pd.DataFrame,\n",
        "    X_test: pd.DataFrame,\n",
        "    y_train: pd.Series = None,\n",
        "    y_test: pd.Series = None,\n",
        "    custom_mapping: Dict[str, Dict[str, int]] = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Simplified version using manual one-hot encoding to avoid sklearn issues.\n",
        "    \"\"\"\n",
        "\n",
        "    # Default mapping\n",
        "    default_mapping = {\n",
        "        'Previous Treatment': {'no': 0, 'yes': 1},\n",
        "        'NCI Risk': {'standard': 0, 'high': 1},\n",
        "        'Sex': {'male': 0, 'female': 1},\n",
        "        'Lineage': {'b': 0, 't': 1},\n",
        "        'Bulky Disease': {'no': 0, 'yes': 1},\n",
        "        'Prednisolone Response': {'good': 0, 'poor': 1},\n",
        "        'CNS Disease': {'no': 0, 'yes': 1},\n",
        "        'Cytogenetic groups ': {'non-high risk': 1, 'not required': 2, 'high risk': 3},\n",
        "        'Provisional risk': {'standard': 0, 'intermediate': 1, 'high': 2, 't': 3},\n",
        "        'MRD Status_EOI': {'negative': 1, 'not required': 2, 'positive': 3},\n",
        "        'Final Risk ': {'standard': 0, 'intermediate': 1, 'high': 2, 't': 3},\n",
        "        'Relapsed': {'no': 0, 'yes': 1}\n",
        "    }\n",
        "\n",
        "    mapping = custom_mapping if custom_mapping is not None else default_mapping\n",
        "    X_train_encoded = X_train.copy()\n",
        "    X_test_encoded = X_test.copy()\n",
        "    encoding_info = {'label_mapping': {}}\n",
        "\n",
        "    # Encode target\n",
        "    y_train_encoded, y_test_encoded = None, None\n",
        "    if y_train is not None and y_test is not None:\n",
        "        if 'Relapsed' in mapping:\n",
        "            # Create mapping function\n",
        "            relapsed_map = mapping['Relapsed']\n",
        "            y_train_encoded = y_train.map(lambda x: relapsed_map.get(str(x).lower(), 0)).astype(int)\n",
        "            y_test_encoded = y_test.map(lambda x: relapsed_map.get(str(x).lower(), 0)).astype(int)\n",
        "            encoding_info['label_mapping']['Relapsed'] = mapping['Relapsed']\n",
        "\n",
        "    # Manual one-hot encoding for 'Detail cytogenetics'\n",
        "    if 'Detail cytogenetics' in X_train_encoded.columns:\n",
        "        try:\n",
        "            # Get all unique categories from training data\n",
        "            unique_categories = X_train_encoded['Detail cytogenetics'].fillna('unknown').astype(str).unique()\n",
        "\n",
        "            # Create one-hot encoded columns for training data\n",
        "            for category in unique_categories:\n",
        "                col_name = f\"cytogenetics_{category}\"\n",
        "                X_train_encoded[col_name] = (X_train_encoded['Detail cytogenetics'].fillna('unknown').astype(str) == category).astype(int)\n",
        "\n",
        "            # Create same columns for test data (some might be all zeros)\n",
        "            for category in unique_categories:\n",
        "                col_name = f\"cytogenetics_{category}\"\n",
        "                X_test_encoded[col_name] = (X_test_encoded['Detail cytogenetics'].fillna('unknown').astype(str) == category).astype(int)\n",
        "\n",
        "            # Drop original column\n",
        "            X_train_encoded = X_train_encoded.drop('Detail cytogenetics', axis=1)\n",
        "            X_test_encoded = X_test_encoded.drop('Detail cytogenetics', axis=1)\n",
        "\n",
        "            encoding_info['onehot_features'] = [f\"cytogenetics_{cat}\" for cat in unique_categories]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Manual one-hot encoding failed: {e}\")\n",
        "            # Fallback to label encoding\n",
        "            X_train_encoded['Detail cytogenetics'] = X_train_encoded['Detail cytogenetics'].astype('category').cat.codes\n",
        "            X_test_encoded['Detail cytogenetics'] = X_test_encoded['Detail cytogenetics'].astype('category').cat.codes\n",
        "\n",
        "    # Apply label encoding to other columns\n",
        "    for column, value_map in mapping.items():\n",
        "        if column != 'Relapsed' and column in X_train_encoded.columns:\n",
        "            # Create a mapping function for this specific column\n",
        "            def map_value(x, mapping_dict=value_map):\n",
        "                x_str = str(x).lower().strip() if pd.notna(x) else 'unknown'\n",
        "                return mapping_dict.get(x_str, 0)  # Default to 0 for unknown values\n",
        "\n",
        "            X_train_encoded[column] = X_train_encoded[column].apply(map_value)\n",
        "            if column in X_test_encoded.columns:\n",
        "                X_test_encoded[column] = X_test_encoded[column].apply(map_value)\n",
        "            encoding_info['label_mapping'][column] = value_map\n",
        "\n",
        "    # Handle any remaining categorical columns\n",
        "    categorical_cols = X_train_encoded.select_dtypes(include=['object', 'category']).columns\n",
        "    for col in categorical_cols:\n",
        "        if col not in encoding_info['label_mapping']:\n",
        "            X_train_encoded[col] = X_train_encoded[col].astype('category').cat.codes\n",
        "            X_test_encoded[col] = X_test_encoded[col].astype('category').cat.codes\n",
        "            encoding_info['label_mapping'][col] = 'categorical_encoding_auto'\n",
        "\n",
        "    # Ensure all columns are numeric\n",
        "    X_train_encoded = X_train_encoded.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
        "    X_test_encoded = X_test_encoded.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
        "\n",
        "    print(\"Encoding completed successfully!\")\n",
        "    print(f\"X_train shape after encoding: {X_train_encoded.shape}\")\n",
        "    print(f\"X_test shape after encoding: {X_test_encoded.shape}\")\n",
        "\n",
        "    return X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded, encoding_info"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fscBUp0mx5AJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/Icicle Pre trial AI paper dataset_anonymised_April 2025.xlsx\"\n",
        "df = pd.read_excel(file_path)"
      ],
      "metadata": {
        "id": "V6K5_VWIh2Ra"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''df_clean = remove_columns(df, feature_set='minimal')\n",
        "print(df_clean.columns.tolist())'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4AcGTKteiNg-",
        "outputId": "301bdc7b-12c8-4528-ce48-38fe1ca06b53"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"df_clean = remove_columns(df, feature_set='minimal')\\nprint(df_clean.columns.tolist())\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = remove_columns(df, feature_set='normal')\n",
        "print(df_clean.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa65b06-a166-443c-febb-8170dafcb817",
        "id": "L-IhWAQQ_jTp"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Previous Treatment', 'NCI Risk', 'Sex', 'Age', 'Lineage', 'Bulky Disease', 'Highest presenting WBC', 'Prednisolone Response', 'CNS Disease', 'Cytogenetic groups ', 'Detail cytogenetics', 'Provisional risk', 'MRD Status_EOI', 'Final Risk ', 'Relapsed']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = clean_string_columns(df_clean, ['Previous Treatment', 'NCI Risk', 'Sex', 'Lineage', 'Bulky Disease', 'Prednisolone Response', 'CNS Disease', 'Cytogenetic groups ', 'Detail cytogenetics', 'Provisional risk', 'MRD Status_EOI', 'Final Risk ', 'Relapsed'])"
      ],
      "metadata": {
        "id": "v4-E2RTio9lG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove entry which are not in remission\n",
        "df_clean = filter_remission_status(df_clean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZXgn7aYrIeA",
        "outputId": "a5e0a280-726f-4656-cbff-551f96ff60fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'Remission status _EOI' not found in the DataFrame.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the indices of the test data\n",
        "test_indices = loaded_X_test.index\n",
        "\n",
        "# Extract training data by excluding test indices\n",
        "X_train = df_clean.drop(test_indices).drop('Relapsed', axis=1)  # Replace 'target_column'\n",
        "y_train = df_clean.drop(test_indices)['Relapsed']  # Replace 'target_column'\n",
        "\n",
        "# Verify the reconstruction\n",
        "print(f\"Full data shape: {df_clean.shape}\")\n",
        "print(f\"X_test shape: {loaded_X_test.shape}\")\n",
        "print(f\"y_test shape: {loaded_y_test.shape}\")\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"Total samples: {len(X_train) + len(loaded_X_test)} == {len(df_clean)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmhZ8kcOuklw",
        "outputId": "3010ff9c-d949-4768-fb7d-05facc888e82"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full data shape: (2331, 15)\n",
            "X_test shape: (467, 14)\n",
            "y_test shape: (467, 1)\n",
            "X_train shape: (1864, 14)\n",
            "y_train shape: (1864,)\n",
            "Total samples: 2331 == 2331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Mount Google Drive (if not already mounted)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to save the files in your Drive\n",
        "# Using the same folder as the test data for consistency\n",
        "save_path = '/content/drive/MyDrive/test_data/'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save X_train and y_train to CSV files\n",
        "X_train_path = os.path.join(save_path, 'X_train.csv')\n",
        "y_train_path = os.path.join(save_path, 'y_train.csv')\n",
        "\n",
        "X_train.to_csv(X_train_path, index=False)\n",
        "y_train.to_csv(y_train_path, index=False)\n",
        "\n",
        "print(f\"X_train saved to: {X_train_path}\")\n",
        "print(f\"y_train saved to: {y_train_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrUixb9VwtXt",
        "outputId": "8f8053fa-d399-464e-e0c4-9b9543b23f49"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "X_train saved to: /content/drive/MyDrive/test_data/X_train.csv\n",
            "y_train saved to: /content/drive/MyDrive/test_data/y_train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to save the files in your Drive\n",
        "# You might want to create a specific folder for your data\n",
        "save_path = '/content/drive/MyDrive/test_data/'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "import os\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save X_test and y_test to CSV files\n",
        "X_test_path = os.path.join(save_path, 'X_test.csv')\n",
        "y_test_path = os.path.join(save_path, 'y_test.csv')\n",
        "\n",
        "X_test.to_csv(X_test_path, index=False)\n",
        "y_test.to_csv(y_test_path, index=False)\n",
        "\n",
        "print(f\"X_test saved to: {X_test_path}\")\n",
        "print(f\"y_test saved to: {y_test_path}\")\n",
        "\n",
        "# --- Code to load the data back from Drive ---\n",
        "# (You can run this in a new session or after a runtime restart)\n",
        "\n",
        "# Mount Google Drive (if not already mounted)\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Define the path where the files are saved\n",
        "# load_path = '/content/drive/MyDrive/test_data/' # Use the same path as save_path\n",
        "\n",
        "# Load X_test and y_test from CSV files\n",
        "# loaded_X_test = pd.read_csv(os.path.join(load_path, 'X_test.csv'))\n",
        "# loaded_y_test = pd.read_csv(os.path.join(load_path, 'y_test.csv'))\n",
        "\n",
        "# Display the loaded data (optional)\n",
        "# print(\"\\nLoaded X_test:\")\n",
        "# display(loaded_X_test.head())\n",
        "# print(\"\\nLoaded y_test:\")\n",
        "# display(loaded_y_test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hTEEKFe-nVf",
        "outputId": "6616265a-7efc-40fe-f746-29eebfe9c560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "X_test saved to: /content/drive/MyDrive/test_data/X_test.csv\n",
            "y_test saved to: /content/drive/MyDrive/test_data/y_test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BbSxQM8_x_Bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_test, y_test = load_train_test_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12RekQxCxrWb",
        "outputId": "e8bb3229-1479-4e3e-cd49-97fc0eff7360"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully.\n",
            "Data loaded successfully!\n",
            "X_train shape: (1864, 14)\n",
            "y_train shape: (1864, 1)\n",
            "X_test shape: (467, 14)\n",
            "y_test shape: (467, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define column types\n",
        "categorical_cols = ['Previous Treatment', 'NCI Risk', 'Sex', 'Lineage', 'Bulky Disease', 'Prednisolone Response', 'CNS Disease', 'Cytogenetic groups ', 'Detail cytogenetics', 'Provisional risk', 'MRD Status_EOI', 'Final Risk ']\n",
        "numeric_cols = ['Age', 'Highest presenting WBC']\n",
        "\n",
        "# Apply safe imputation\n",
        "X_train_imputed, X_test_imputed, fitted_imputers = impute_train_test(\n",
        "    X_train,\n",
        "    X_test,\n",
        "    categorical_cols,\n",
        "    numeric_cols,\n",
        "    numeric_strategy=\"median\"\n",
        ")\n",
        "\n",
        "# The fitted imputers can be saved and reused for new patient data"
      ],
      "metadata": {
        "id": "HqWJFWioy797"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unTs9JK16PfQ",
        "outputId": "0cfcc61d-7623-430a-8bd1-13b6581047c1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in X_train_imputed:\n",
            "Previous Treatment        0\n",
            "NCI Risk                  0\n",
            "Sex                       0\n",
            "Age                       0\n",
            "Lineage                   0\n",
            "Bulky Disease             0\n",
            "Highest presenting WBC    0\n",
            "Prednisolone Response     0\n",
            "CNS Disease               0\n",
            "Cytogenetic groups        0\n",
            "Detail cytogenetics       0\n",
            "Provisional risk          0\n",
            "MRD Status_EOI            0\n",
            "Final Risk                0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in X_test_imputed:\n",
            "Previous Treatment        0\n",
            "NCI Risk                  0\n",
            "Sex                       0\n",
            "Age                       0\n",
            "Lineage                   0\n",
            "Bulky Disease             0\n",
            "Highest presenting WBC    0\n",
            "Prednisolone Response     0\n",
            "CNS Disease               0\n",
            "Cytogenetic groups        0\n",
            "Detail cytogenetics       0\n",
            "Provisional risk          0\n",
            "MRD Status_EOI            0\n",
            "Final Risk                0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in y_train:\n",
            "Relapsed    0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in y_test:\n",
            "0    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded, encoding_info = encode_data(\n",
        "        X_train_imputed, X_test_imputed, y_train, y_test\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKax1r3c1Sv7",
        "outputId": "55db4103-eba0-4088-a583-13efae5c8dd1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: One-hot encoding failed for 'Detail cytogenetics': input_features is not equal to feature_names_in_\n",
            "Encoding completed successfully!\n",
            "X_train shape after encoding: (1864, 14)\n",
            "X_test shape after encoding: (467, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_imputed['Detail cytogenetics'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbKlWC_VAhoo",
        "outputId": "6208cf86-2797-44d8-f707-30ea279ed453"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['etv6-runx1' 'high hyperdiploidy' 'b-other' 'hypodiploidy' 'tcf3-pbx1'\n",
            " 'bcr-abl1' 'kmt2a rearranged' 'iamp21' 'tcf3-hlf' 'not required'\n",
            " 'near triploidy/tetraploidy' 'tetraploidy' 'near triploidy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded, encoding_info = encode_data_simple(\n",
        "    X_train_imputed, X_test_imputed, y_train, y_test\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZxpELVE9sfZ",
        "outputId": "e12773f7-8e18-4e2f-903b-21f3920c1da3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding completed successfully!\n",
            "X_train shape after encoding: (1864, 26)\n",
            "X_test shape after encoding: (467, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_encoded.dtypes)\n",
        "print(X_test_encoded.dtypes)\n",
        "print(y_train_encoded.dtypes)\n",
        "print(y_test_encoded.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJEB9e666-k4",
        "outputId": "dbc3190f-317a-473e-aef4-b496d984baeb"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous Treatment                           int64\n",
            "NCI Risk                                     int64\n",
            "Sex                                          int64\n",
            "Age                                        float64\n",
            "Lineage                                      int64\n",
            "Bulky Disease                                int64\n",
            "Highest presenting WBC                     float64\n",
            "Prednisolone Response                        int64\n",
            "CNS Disease                                  int64\n",
            "Cytogenetic groups                           int64\n",
            "Provisional risk                             int64\n",
            "MRD Status_EOI                               int64\n",
            "Final Risk                                   int64\n",
            "cytogenetics_etv6-runx1                      int64\n",
            "cytogenetics_high hyperdiploidy              int64\n",
            "cytogenetics_b-other                         int64\n",
            "cytogenetics_hypodiploidy                    int64\n",
            "cytogenetics_tcf3-pbx1                       int64\n",
            "cytogenetics_bcr-abl1                        int64\n",
            "cytogenetics_kmt2a rearranged                int64\n",
            "cytogenetics_iamp21                          int64\n",
            "cytogenetics_tcf3-hlf                        int64\n",
            "cytogenetics_not required                    int64\n",
            "cytogenetics_near triploidy/tetraploidy      int64\n",
            "cytogenetics_tetraploidy                     int64\n",
            "cytogenetics_near triploidy                  int64\n",
            "dtype: object\n",
            "Previous Treatment                           int64\n",
            "NCI Risk                                     int64\n",
            "Sex                                          int64\n",
            "Age                                        float64\n",
            "Lineage                                      int64\n",
            "Bulky Disease                                int64\n",
            "Highest presenting WBC                     float64\n",
            "Prednisolone Response                        int64\n",
            "CNS Disease                                  int64\n",
            "Cytogenetic groups                           int64\n",
            "Provisional risk                             int64\n",
            "MRD Status_EOI                               int64\n",
            "Final Risk                                   int64\n",
            "cytogenetics_etv6-runx1                      int64\n",
            "cytogenetics_high hyperdiploidy              int64\n",
            "cytogenetics_b-other                         int64\n",
            "cytogenetics_hypodiploidy                    int64\n",
            "cytogenetics_tcf3-pbx1                       int64\n",
            "cytogenetics_bcr-abl1                        int64\n",
            "cytogenetics_kmt2a rearranged                int64\n",
            "cytogenetics_iamp21                          int64\n",
            "cytogenetics_tcf3-hlf                        int64\n",
            "cytogenetics_not required                    int64\n",
            "cytogenetics_near triploidy/tetraploidy      int64\n",
            "cytogenetics_tetraploidy                     int64\n",
            "cytogenetics_near triploidy                  int64\n",
            "dtype: object\n",
            "Relapsed    int64\n",
            "dtype: object\n",
            "0    int64\n",
            "dtype: object\n"
          ]
        }
      ]
    }
  ]
}